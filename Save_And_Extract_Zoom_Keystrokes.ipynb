#modified to save strokes to a file, so it speeds up generating the mel specs

#amended to save many mel specs

import librosa
import librosa.display
import matplotlib.pyplot as plt
import numpy as np
import torchaudio
import torchaudio.transforms as T  # Import torchaudio transforms for SpecAugment
import os
import random
import torch
import torch.nn.functional as F
from torch_audiomentations import PitchShift #TimeStretch doesn't exist in the latest torch_audiomentation package
import librosa
import torchaudio.transforms as T
import torch
import random
from librosa.effects import time_stretch as librosa_time_stretch
import pickle
# Function to apply warping (pitch shift + time stretch) on waveform numpy array


def apply_warping_librosa(waveform_np, sample_rate):
    waveform = torch.tensor(waveform_np, dtype=torch.float32).unsqueeze(0)

    # Random semitone shift between -4 and 4
    n_steps = random.uniform(-4, 4)

    try:
        pitch_shift = T.PitchShift(sample_rate=sample_rate, n_steps=n_steps)
        with torch.no_grad():
            warped = pitch_shift(waveform)
        warped_np = warped.squeeze(0).numpy()
        return warped_np
    except Exception as e:
        print(f"Warning: pitch shifting failed with error: {e}. Returning original waveform.")
        return waveform_np

# Function to process all audio files in a directory
def process_directory(directory, size, scan, before, after, show=False):
    all_keystrokes = []

    for filename in sorted(os.listdir(directory), key=lambda x: x.lower()):
        file_path = os.path.join(directory, filename)
        print(f"Found file: {filename}")

        if os.path.isfile(file_path) and filename.lower().endswith('.wav'):
            print(f"Processing file: {filename}")

            try:
                waveform, sample_rate = torchaudio.load(file_path)
                waveform = waveform.numpy().flatten()

                prom = 0.6
                step = 0.1
                strokes = []

                while len(strokes) != 25:
                    strokes = isolator(
                        waveform[1 * sample_rate:], sample_rate, size, scan, before, after, prom, show, time_shift=False
                    )

                    if len(strokes) < 25:
                        prom -= step
                    elif len(strokes) > 25:
                        prom += step

                    if prom <= 0:
                        print(f"-- Not possible to extract 25 strokes from {filename}")
                        break

                    step *= 0.99

                print(f"Final threshold for {filename}: {prom}")
                print(f"Extracted {len(strokes)} strokes for {filename}")

                all_keystrokes.extend([(filename, stroke) for stroke in strokes])

            except Exception as e:
                print(f"Error processing {filename}: {e}")

    return all_keystrokes, sample_rate

def time_shift_waveform(waveform, max_shift_percentage):
    """Applies a random time shift to the waveform."""
    max_shift = int(len(waveform) * max_shift_percentage)
    shift = random.randint(-max_shift, max_shift)
    return np.roll(waveform, shift)

# Function to isolate keystrokes from the signal
def isolator(signal, sample_rate, size, scan, before, after, threshold, show, time_shift=True):
    strokes = []
    signal = signal.flatten()

    # Compute STFT for energy detection
    fft = librosa.stft(signal, n_fft=size, hop_length=scan)
    energy = np.abs(np.sum(fft, axis=0)).astype(float)

    # Apply thresholding to detect peaks
    threshed = energy > threshold
    peaks = np.where(threshed)[0]

    prev_end = 0
    for peak in peaks:
        timestamp = (peak * scan) + size // 2
        if timestamp > prev_end + (0.1 * sample_rate):
            keystroke = signal[timestamp - before:timestamp + after]

            if len(keystroke) > 0:
                if time_shift:
                    keystroke = time_shift_waveform(keystroke, max_shift_percentage=0.4)

                strokes.append(keystroke)
                prev_end = timestamp + after

    return strokes

def save_mel_spectrograms(all_keystrokes, sample_rate, size, scan, output_dir):
    os.makedirs(output_dir, exist_ok=True)

    time_masking = T.TimeMasking(time_mask_param=15)  # Less aggressive time masking
    freq_masking = T.FrequencyMasking(freq_mask_param=5)  # Less frequency masking

    for i, (filename, stroke) in enumerate(all_keystrokes):
        stroke_np = np.array(stroke).flatten()

        if len(stroke_np) == 0:
            print(f"Skipping empty stroke at index {i}")
            continue

        try:
            versions = [
                ("v0", stroke_np, False),  # Original, no spec augment
                ("v1", stroke_np, True),  # SpecAug
                ("v2", time_shift_waveform(stroke_np, max_shift_percentage=0.4), True),  # TimeShift + SpecAug
                ("v3", apply_warping_librosa(time_shift_waveform(stroke_np, max_shift_percentage=0.2), sample_rate), True),
                ("v4", apply_warping_librosa(stroke_np, sample_rate), True),
                ("v5", stroke_np, True),  # SpecAug
                ("v6", stroke_np, True),  # SpecAug
                ("v7", time_shift_waveform(stroke_np, max_shift_percentage=0.4), True),  # TimeShift + SpecAug
                ("v8", apply_warping_librosa(time_shift_waveform(stroke_np, max_shift_percentage=0.4), sample_rate), True),
                ("v9", apply_warping_librosa(stroke_np, sample_rate), True),
                ("v10", stroke_np, True), #Specaug
                ("v11", stroke_np, True),  # SpecAug
                ("v12", time_shift_waveform(stroke_np, max_shift_percentage=0.4), True),  # TimeShift + SpecAug
                ("v13", apply_warping_librosa(time_shift_waveform(stroke_np, max_shift_percentage=0.2), sample_rate), True),
                ("v14", apply_warping_librosa(stroke_np, sample_rate), True),
                ("v15", stroke_np, True),  # SpecAug
                ("v16", stroke_np, True),  # SpecAug
                ("v17", time_shift_waveform(stroke_np, max_shift_percentage=0.4), True),  # TimeShift + SpecAug
                ("v18", apply_warping_librosa(time_shift_waveform(stroke_np, max_shift_percentage=0.4), sample_rate), True),
                ("v19", apply_warping_librosa(stroke_np, sample_rate), True),
            ]

            # Remove extension from original filename
            base_filename = os.path.splitext(filename)[0]

            for version_id, waveform_np, apply_aug in versions:
                if len(waveform_np) == 0:
                    print(f"Skipping empty waveform for {version_id} of stroke {i}")
                    continue
                #Compute mel spectrogram
                S = librosa.feature.melspectrogram(y=waveform_np, sr=sample_rate, n_fft=size, hop_length=scan)
                S_DB = librosa.power_to_db(S, ref=np.max)
                #Convert to Torch tensor for torchaudio transformations
                S_DB_tensor = torch.tensor(S_DB, dtype=torch.float32)

                if apply_aug:
                    S_DB_tensor = time_masking(S_DB_tensor.unsqueeze(0)).squeeze(0)
                    S_DB_tensor = freq_masking(S_DB_tensor.unsqueeze(0)).squeeze(0)

                #Z score normalisation added, prior to resizing tensors and saving
                mean=S_DB_tensor.mean()
                std=S_DB_tensor.std()
                S_DB_tensor=(S_DB_tensor-mean)/std

                augmented_spec_np = S_DB_tensor.numpy()
                #Attempting to make processing quicker by not saving .pngs, ONLY .PTs
                #plt.figure(figsize=(10, 4))
                #librosa.display.specshow(augmented_spec_np, sr=sample_rate, hop_length=scan, x_axis='time', y_axis='mel', fmax=16384)
                #plt.colorbar(format='%+2.0f dB')
                #plt.title(f'Augmented Mel-Spectrogram {i+1} {version_id}')
                #plt.tight_layout()

                #output_path = os.path.join(output_dir, f"{base_filename}_mel_spec_{i+1}_{version_id}.png")
                #plt.savefig(output_path)
                #plt.close()
                #print(f"Saved augmented mel-spectrogram to {output_path}")

                # Save resized tensor
                tensor_resized = S_DB_tensor.unsqueeze(0).unsqueeze(0) #Adds batch dimensions and channel dimensions [1, 1, H, W]
                #resizes spatial dimensions from 128, 87 to 224 x 224 i.e. [1, 1, 224, 224]
                tensor_resized = F.interpolate(tensor_resized, size=(224, 224), mode='bilinear', align_corners=False)
                tensor_resized = tensor_resized.squeeze(0) #Removes one dimension i.e. [1, 224, 224]

                tensor_output_path = os.path.join(output_dir, f"{base_filename}_mel_spec_{i+1}_{version_id}.pt")
                torch.save(tensor_resized, tensor_output_path)
                print(f"Saved tensor to {tensor_output_path}")

              #png_path = os.path.join(output_dir, f"mel_spectrogram_{i+1}.png")
              #plt.savefig(png_path)
              #plt.close()
              #print(f"Saved mel-spectrogram PNG to {png_path}")

        except Exception as e:
            print(f"Error computing mel-spectrogram for stroke {i}: {e}")

# Main function to run the process
def main():
    directory = '/content/drive/MyDrive/ColabNotebooks/ZoomRecordings'
    size = 2048
    scan = 256
    before = 11025
    after = 11025
    show = False
    strokes_file = "saved_strokes2.pk1"

    if os.path.exists(strokes_file):
            print(f"{strokes_file} found.")
            choice = input("Load existing strokes? (y/n): ").strip().lower()
            if choice == 'y':
                with open(strokes_file, "rb") as f:
                    data = pickle.load(f)
                    all_keystrokes = data["keystrokes"]
                    sample_rate = data["sample_rate"]
                print(f"Loaded {len(all_keystrokes)} strokes from file.")
            else:
                all_keystrokes, sample_rate = process_directory(directory, size, scan, before, after, show)
                with open(strokes_file, "wb") as f:
                    pickle.dump({
                        "keystrokes": all_keystrokes,
                        "sample_rate": sample_rate
                    }, f)
                print("Saved new strokes to file.")
    else:
        all_keystrokes, sample_rate = process_directory(directory, size, scan, before, after, show)
        with open(strokes_file, "wb") as f:
            pickle.dump({
                    "keystrokes": all_keystrokes,
                    "sample_rate": sample_rate
                }, f)
        print("Saved new strokes to file.")

    #all_keystrokes, sample_rate = process_directory(directory, size, scan, before, after, show)
    print(f"Total keystrokes found: {len(all_keystrokes)}")

    # Define the output directory to store both tensors and PNGs
    output_dir = "/content/drive/MyDrive/ColabNotebooks/ZoomRecordings/ZoomTensorsOnly"
    save_mel_spectrograms(all_keystrokes, sample_rate, size, scan, output_dir)

if __name__ == "__main__":
    main()
