#Extracting keystrokes, augmenting and saving to Google Drive as tensors

#modified to perform z score normalisation and resizing of tensors prior to saving to google drive
#MODIFIED TO PRINT 19 MEL SPECS PER KEYSTROKE

import librosa
import librosa.display
import matplotlib.pyplot as plt
import numpy as np
import torchaudio
import torchaudio.transforms as T  # Import torchaudio transforms for SpecAugment
import os
import random
import torch
import torch.nn.functional as F
from torch_audiomentations import PitchShift #TimeStretch doesn't exist in the latest torch_audiomentation package
import pickle

# Function to apply warping (pitch shift + time stretch on waveform numpy array
def apply_warping(waveform_np, sample_rate):
    """
    Apply pitch shift and time stretch warping on a numpy waveform.
    Returns warped waveform as numpy array.
    """
    waveform = torch.tensor(waveform_np, dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # shape (1,1,length)

    pitch_shift = PitchShift(sample_rate=sample_rate, p=1.0)
    semitones = torch.tensor([random.uniform(-4,4)])

    with torch.no_grad():
        warped = pitch_shift(waveform)

    warped_np = warped.squeeze(0).squeeze(0).numpy()
    return warped_np

# Function to process all audio files in a directory
def process_directory(directory, size, scan, before, after, show=False):
    all_keystrokes = []

    for filename in sorted(os.listdir(directory), key=lambda x: x.lower()):  # Processes the files numerically in order
        file_path = os.path.join(directory, filename)

        print(f"Found file: {filename}")

        if os.path.isfile(file_path) and filename.lower().endswith('.wav'):
            print(f"Processing file: {filename}")

            try:
                waveform, sample_rate = torchaudio.load(file_path)
                waveform = waveform.numpy().flatten()

                prom = 0.6
                step = 0.1
                strokes = []

                while len(strokes) != 25:
                    strokes = isolator(
                        waveform[1 * sample_rate:], sample_rate, size, scan, before, after, prom, show,
                        time_shift=True, apply_warp=False
                    )

                    if len(strokes) < 25:
                        prom -= step
                    elif len(strokes) > 25:
                        prom += step

                    if prom <= 0:
                        print(f"-- Not possible to extract 25 strokes from {filename}")
                        break

                    step *= 0.99

                print(f"Final threshold for {filename}: {prom}")
                print(f"Extracted {len(strokes)} strokes for {filename}")

                # Store strokes along with filename for labeling
                all_keystrokes.extend([(stroke, filename) for stroke in strokes])

            except Exception as e:
                print(f"Error processing {filename}: {e}")

    return all_keystrokes, sample_rate

# Function to randomly shift waveform
def time_shift_waveform(waveform, max_shift_percentage):
    """Applies a random time shift to the waveform."""
    max_shift = int(len(waveform) * max_shift_percentage)
    shift = random.randint(-max_shift, max_shift)
    return np.roll(waveform, shift)

# Function to isolate keystrokes from the signal and apply warping
def isolator(signal, sample_rate, size, scan, before, after, threshold, show, time_shift=True, apply_warp=True):
    strokes = []
    signal = signal.flatten()

    # Compute STFT for energy detection
    fft = librosa.stft(signal, n_fft=size, hop_length=scan)
    energy = np.abs(np.sum(fft, axis=0)).astype(float)

    # Apply thresholding to detect peaks
    threshed = energy > threshold
    peaks = np.where(threshed)[0]

    prev_end = 0
    for peak in peaks:
        timestamp = (peak * scan) + size // 2
        if timestamp > prev_end + (0.1 * sample_rate):
            keystroke = signal[timestamp - before:timestamp + after]

            if len(keystroke) > 0:
                if time_shift:
                    keystroke = time_shift_waveform(keystroke, max_shift_percentage=0.4)

                if apply_warp:
                    keystroke = apply_warping(keystroke, sample_rate)

                strokes.append(keystroke)
                prev_end = timestamp + after

    return strokes

def save_mel_spectrograms(all_keystrokes_with_filenames, sample_rate, size, scan, output_dir):
    os.makedirs(output_dir, exist_ok=True)

    time_masking = T.TimeMasking(time_mask_param=5)  # Less aggressive time masking
    freq_masking = T.FrequencyMasking(freq_mask_param=5)  # Less frequency masking

    for i, (stroke, filename) in enumerate(all_keystrokes_with_filenames):
        stroke_np = np.array(stroke).flatten()

        if len(stroke_np) == 0:
            print(f"Skipping empty stroke at index {i}")
            continue

        try:

            versions = [
                ("v0", stroke_np, False),  # Original, no spec augment
                ("v1", stroke_np, True),  # SpecAug
                ("v2", time_shift_waveform(stroke_np, max_shift_percentage=0.4), True),  # TimeShift + SpecAug
                ("v3", time_shift_waveform(stroke_np, max_shift_percentage=0.4), True),  # TimeShift + SpecAug
                ("v4", apply_warping(stroke_np, sample_rate), True),
                ("v5", stroke_np, True),  # SpecAug
                ("v6", time_shift_waveform(stroke_np, max_shift_percentage=0.25), True),  # TimeShift + SpecAug
                ("v7", time_shift_waveform(stroke_np, max_shift_percentage=0.4), True),  # TimeShift + SpecAug
                ("v8", apply_warping(stroke_np, sample_rate), True),
                ("v9", stroke_np, True),  # SpecAug
                ("v10", stroke_np, False),  # Original, no spec augment
                ("v11", stroke_np, True),  # SpecAug
                ("v12", time_shift_waveform(stroke_np, max_shift_percentage=0.4), True),  # TimeShift + SpecAug
                ("v13", time_shift_waveform(stroke_np, max_shift_percentage=0.4), True),  # TimeShift + SpecAug
                ("v14", apply_warping(stroke_np, sample_rate), True),
                ("v15", stroke_np, True),  # SpecAug
                ("v16", time_shift_waveform(stroke_np, max_shift_percentage=0.25), True),  # TimeShift + SpecAug
                ("v17", time_shift_waveform(stroke_np, max_shift_percentage=0.4), True),  # TimeShift + SpecAug
                ("v18", apply_warping(stroke_np, sample_rate), True),
                ("v19", stroke_np, True),  # SpecAug
                ]

            # Remove extension from original filename
            base_filename = os.path.splitext(filename)[0]

            for version_id, waveform_np, apply_aug in versions:
                if len(waveform_np) == 0:
                    print(f"Skipping empty waveform for {version_id} of stroke {i}")
                    continue
            # Compute mel spectrogram
                S = librosa.feature.melspectrogram(y=stroke_np, sr=sample_rate, n_fft=size, hop_length=scan)
                S_DB = librosa.power_to_db(S, ref=np.max)

                # Convert to Torch tensor for torchaudio transformations
                S_DB_tensor = torch.tensor(S_DB, dtype=torch.float32)
                if apply_aug:
                    S_DB_tensor = time_masking(S_DB_tensor.unsqueeze(0)).squeeze(0)
                    S_DB_tensor = freq_masking(S_DB_tensor.unsqueeze(0)).squeeze(0)

                #Z score normalisation added, prior to resizing tensors and saving
                mean=S_DB_tensor.mean()
                std=S_DB_tensor.std()
                S_DB_tensor=(S_DB_tensor-mean)/std

                augmented_spec_np = S_DB_tensor.numpy()
            # Apply SpecAugment-like transformations using torchaudio (50% probability)
            #if random.random() < 0.5:
            # Convert back to NumPy for visualization
            #augmented_spec_np = S_DB_tensor.numpy()

                # Plot and save augmented spectrogram with unique filename
                plt.figure(figsize=(10, 4))
                librosa.display.specshow(
                    augmented_spec_np, sr=sample_rate, hop_length=scan,
                    x_axis='time', y_axis='mel', fmax=16384
                )
                plt.colorbar(format='%+2.0f dB')
                plt.title(f'Augmented Mel-Spectrogram {i+1} ({filename})')
                plt.tight_layout()

                # Unique filenames with version and original filename
                output_path = os.path.join(output_dir, f"{base_filename}_mel_spec_{i+1}_{version_id}.png")
                plt.savefig(output_path)
                plt.close()
                print(f"Saved augmented mel-spectrogram to {output_path}")

                # Save resized tensor
                tensor_resized = S_DB_tensor.unsqueeze(0).unsqueeze(0) #Adds batch dimensions and channel dimensions [1, 1, H, W]
                #resizes spatial dimensions from 128, 87 to 224 x 224 i.e. [1, 1, 224, 224]
                tensor_resized = F.interpolate(tensor_resized, size=(224, 224), mode='bilinear', align_corners=False)
                tensor_resized = tensor_resized.squeeze(0) #Removes one dimension i.e. [1, 224, 224]

                tensor_output_path = os.path.join(output_dir, f"{base_filename}_mel_spec_{i+1}_{version_id}.pt")
                torch.save(tensor_resized, tensor_output_path)
                print(f"Saved tensor to {tensor_output_path}")

        except Exception as e:
            print(f"Error computing mel-spectrogram for stroke {i}: {e}")

# Main function to run the process
def main():
    directory = '/content/drive/MyDrive/ColabNotebooks/LaptopRecordings'
    size = 2048
    scan = 256  # Hop length. Research paper states this should be 255 for MacBook keystrokes
    before = 6400
    after = 6400
    show = False
    strokes_file = "saved_strokes.pkl"

    if os.path.exists(strokes_file):
            print(f"{strokes_file} found.")
            choice = input("Load existing strokes? (y/n): ").strip().lower()
            if choice == 'y':
                with open(strokes_file, "rb") as f:
                    data = pickle.load(f)
                    all_keystrokes_with_filenames = data["keystrokes"]
                    sample_rate = data["sample_rate"]
                print(f"Loaded {len(all_keystrokes_with_filenames)} strokes from file.")
            else:
                all_keystrokes_with_filenames, sample_rate = process_directory(directory, size, scan, before, after, show)
                with open(strokes_file, "wb") as f:
                    pickle.dump({
                        "keystrokes": all_keystrokes_with_filenames,
                        "sample_rate": sample_rate
                    }, f)
                print("Saved new strokes to file.")
    else:
        all_keystrokes_with_filenames, sample_rate = process_directory(directory, size, scan, before, after, show)
        with open(strokes_file, "wb") as f:
            pickle.dump({
                    "keystrokes": all_keystrokes_with_filenames,
                    "sample_rate": sample_rate
                }, f)
        print("Saved new strokes to file.")


    print(f"Total keystrokes found: {len(all_keystrokes_with_filenames)}")

    output_dir = "/content/drive/MyDrive/ColabNotebooks/LaptopRecordings/MelSpecsOnly11"
    save_mel_spectrograms(all_keystrokes_with_filenames, sample_rate, size, scan, output_dir)

if __name__ == "__main__":
    main()
